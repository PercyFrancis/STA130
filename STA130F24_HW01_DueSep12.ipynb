{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaad910f",
   "metadata": {},
   "source": [
    "# STA130 Week 01 Homework \n",
    "\n",
    "Please see the course [wiki-textbook](https://github.com/pointOfive/stat130chat130/wiki) for the list of topics covered in this homework assignment, and a list of topics that might appear during ChatBot conversations which are \"out of scope\" for the purposes of this homework assignment (and hence can be safely ignored if encountered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aede3d7",
   "metadata": {},
   "source": [
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Introduction</u></summary>\n",
    "\n",
    "### Introduction\n",
    "    \n",
    "A reasonable characterization of STA130 Homework is that it simply defines a weekly reading comprehension assignment. \n",
    "Indeed, STA130 Homework essentially boils down to completing various understanding confirmation exercises oriented around coding and writing tasks.\n",
    "However, rather than reading a textbook, STA130 Homework is based on ChatBots so students can interactively follow up to clarify questions or confusion that they may still have regarding learning objective assignments.\n",
    "\n",
    "> Communication is a fundamental skill underlying statistics and data science, so STA130 Homework based on ChatBots helps practice effective two-way communication as part of a \"realistic\" dialogue activity supporting underlying conceptual understanding building. \n",
    "\n",
    "It will likely become increasingly tempting to rely on ChatBots to \"do the work for you\". But when you find yourself frustrated with a ChatBots inability to give you the results you're looking for, this is a \"hint\" that you've become overreliant on the ChatBots. Your objective should not be to have ChatBots \"do the work for you\", but to use ChatBots to help you build your understanding so you can efficiently leverage ChatBots (and other resources) to help you work more efficiently.<br><br>\n",
    "\n",
    "</details>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Instructions</u></summary>\n",
    "\n",
    "### Instructions\n",
    "    \n",
    "1. Code and write all your answers (for both the \"Prelecture\" and \"Postlecture\" HW) in a python notebook (in code and markdown cells) \n",
    "    \n",
    "> It is *suggested but not mandatory* that you complete the \"Prelecture\" HW prior to the Monday LEC since (a) all HW is due at the same time; but, (b) completing some of the HW early will mean better readiness for LEC and less of a \"procrastentation cruch\" towards the end of the week...\n",
    "    \n",
    "2. Paste summaries of your ChatBot sessions (including link(s) to chat log histories if you're using ChatGPT) within your notebook\n",
    "    \n",
    "> Create summaries of your ChatBot sessions by using concluding prompts such as \"Please provide a summary of our exchanges here so I can submit them as a record of our interactions as part of a homework assignment\" or, \"Please provide me with the final working verson of the code that we created together\"\n",
    "    \n",
    "3. Save your python jupyter notebook in your own account and \"repo\" on [github.com](github.com) and submit a link to that notebook though Quercus for assignment marking<br><br>\n",
    "\n",
    "</details>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Prompt Engineering?</u></summary>\n",
    "\n",
    "### Prompt Engineering?    \n",
    "    \n",
    "The questions (as copy-pasted prompts) are designed to initialize appropriate ChatBot conversations which can be explored in the manner of an interactive and dynamic textbook; but, it is nonetheless **strongly recommendated** that your rephrase the questions in a way that you find natural to ensure a clear understanding of the question. Given sensible prompts the represent a question well, the two primary challenges observed to arise from ChatBots are \n",
    "\n",
    "1. conversations going beyond the intended scope of the material addressed by the question; and, \n",
    "2. unrecoverable confusion as a result of sequential layers logial inquiry that cannot be resolved. \n",
    "\n",
    "In the case of the former (1), adding constraints specifying the limits of considerations of interest tends to be helpful; whereas, the latter (2) is often the result of initial prompting that leads to poor developments in navigating the material, which are likely just best resolve by a \"hard reset\" with a new initial approach to prompting.  Indeed, this is exactly the behavior [hardcoded into copilot](https://answers.microsoft.com/en-us/bing/forum/all/is-this-even-normal/0b6dcab3-7d6c-4373-8efe-d74158af3c00)...\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77293b06",
   "metadata": {},
   "source": [
    "\n",
    "### Marking Rubric (which may award partial credit) \n",
    "\n",
    "- [0.1 points]: All relevant ChatBot summaries [including link(s) to chat log histories if you're using ChatGPT] are reported within the notebook\n",
    "- [0.2 points]: Reasonable well-written general definitions for Question \"2.2\"\n",
    "- [0.3 points]: Demonstrated understanding regarding Question \"4\"\n",
    "<!-- - [0.2 points]: A sensible justification for the choice in Question \"7.4\" -->\n",
    "- [0.4 points]: Requested assessment of ChatBot versus google performance in Question \"8.3\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7d8d5a",
   "metadata": {},
   "source": [
    "## \"Pre-lecture\" HW [*completion prior to next LEC is suggested but not mandatory*]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff4111d",
   "metadata": {},
   "source": [
    "#### 1. Pick one of the datasets from the ChatBot session(s) of the **TUT demo** (or from your own ChatBot session if you wish) and use the code produced through the ChatBot interactions to import the data and confirm that the dataset has missing values<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> If your TA has not shared a relevant ChatBot session from their **TUT demo** through a piazza post and a Quercus announcement, the **TUT notebook** has links to example ChatBot sessions that you can use; or, ...\n",
    "> \n",
    "> ```python\n",
    "> # feel free to just use the following if you prefer...\n",
    "> import pandas as pd\n",
    "> url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "> df = pd.read_csv(url)\n",
    "> df.isna().sum()\n",
    "> ```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c3abcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#               0\n",
       "Name            0\n",
       "Type 1          0\n",
       "Type 2        386\n",
       "HP              0\n",
       "Attack          0\n",
       "Defense         0\n",
       "Sp. Atk         0\n",
       "Sp. Def         0\n",
       "Speed           0\n",
       "Generation      0\n",
       "Legendary       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebea424",
   "metadata": {},
   "source": [
    "#### 2. Start a new ChatBot session with an initial prompt introducing the dataset you're using and request help to determine how many columns and rows of data a `pandas` DataFrame has, and then\n",
    "\n",
    "1. use code provided in your ChatBot session to print out the number of rows and columns of the dataset; and,  \n",
    "2. write your own general definitions of the meaning of \"observations\" and \"variables\" based on asking the ChatBot to explain these terms in the context of your dataset<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> A good initial prompt to start would be be something like\n",
    "> - \"I've downloaded a dataset about characters from animal crossings (from https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv), and I'd like to know what columns of information I have and how much data I have\"\n",
    "> \n",
    "> You can further reduce the scope of your inquiry with if needed with something like\n",
    "> - \"I've already downloaded the data and want to understand the size (or dimensions) of the dataset to start with\"\n",
    "> \n",
    "> *Some ChatBots can upload your data and do this for you; but, extended usage of this feature [likely requires a paid subscription](https://github.com/pointOfive/stat130chat130/blob/main/CHATLOG/wk1/GPT/SLS/00006_gpt3p5_LoadDataPaywall.md); and, anyway, you need to run the code yourself rather than having a ChatBot do that for you; and, for STA130 we don't want a ChatBot to just do the analysis for us; rather, we instead want ChatBots to help us understand the steps we need to take to analyze the data; so,* **you DO NOT need to purchase an upgraded version of any ChatBots**\n",
    "> - Free-tier level ChatBots like [GPT4o-mini](https://chat.openai.com/) or [Copilot](https://copilot.microsoft.com/) (which is partially based on [ChatGPT4.0](https://chat.openai.com/), and which you have access to through your UofT account) are sufficiently sophisticated and perfectly appropriate for the STA130 course\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bba882e",
   "metadata": {},
   "source": [
    "# 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8df6875a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3190f8d3",
   "metadata": {},
   "source": [
    "# 2.2\n",
    "\n",
    "- Columns are referred as **Variables**.\n",
    "\n",
    "- They are categories that have certain characteristics. All values under the variables contain this characteristic. In the context of the *Pokemon* dataset, it includes 'Type 1', Attack, and so on. Other more general examples include temperature, height, mass etc.\n",
    "\n",
    "- Rows are referred as **Observations**.\n",
    "\n",
    "- Observations contain the actual values that the variables describe. They are specific individuals that possess the characteristics described in the variables. In terms of the *Pokemon* dataset, 'Bulbasaur' and 'Charmander' are examples of this. General examples include names of indiviuals, and serial numbers. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a56c467",
   "metadata": {},
   "source": [
    "#### 3. Ask the ChatBot how you can provide simple summaries of the columns in the dataset and use the suggested code to provide these summaries for your dataset<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> Use your ChatBot session to help you create working examples of using  `df.describe()` and `df['column'].value_counts()` for your dataset (although note that the `.value_counts()` method is not really meant to be used for numeric variables, so if you dataset has only numeric variables, `.value_counts()` might not be particularly informative...)\n",
    ">\n",
    "> #### ChatBot Response Scope \n",
    ">     \n",
    "> If prompts are not sufficiently focused you will likely get overly broad responses from the ChatBot, but you can always respond with subsequent refinement requests to appropriately limit the scope of the ChatBot responses to focus on addressing your actual content targets; so, \n",
    "> - an initially very general inquiry like, \"I need help analyzing my data\" will likely result in a ChatBot response suggesting a wide variety of approaches and techniques for summarizing your dataset; but, re-prompting the ChatBot with something like, \"What's the simplest form of summarization of this dataset that I could do and how do I do it in Python?\" or suggesting guidance using the specific summarization methods requested above will helpfully re-orient the ChatBot to your specific interests and needs\n",
    "> \n",
    "> #### Jupyter Notebook Hints\n",
    "> \n",
    "> Jupyter notebook printouts usaully don't show all of the data (when there's too much to show, like if `df.describe()` includes results for many columns), but the printouts just show enough of the data to give an idea of what the results are which is all we're looking for at the moment\n",
    "> \n",
    "> - Consider dividing the code that ChatBot provides you into different jupyter notebook cells so that each cell concludes with a key printed result; the last line of code in a jupyter notebook cell will automatically print out in a formatted manner, so replacing something like `print(df.head())` with `df.head()` as the last line of a cell provides a sensible way to organize your code\n",
    "> - The printout suggestions above are demonstrated in `STA130F24_CourseProject.ipynb` if looking at an example would be helpful to understand what they're getting at...\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4db30f",
   "metadata": {},
   "source": [
    "According to the chatbot:\n",
    "\n",
    ">To get a simple summary of the columns in your dataset, you can use the .describe() method and the .value_counts() method from the pandas library in Python [1-3]. These methods provide different types of summaries and are suited to different types of data:\n",
    "> - .describe(): This method is useful for numerical data. It returns a summary that includes the count of non-missing values, the mean, standard deviation, minimum and maximum values, and the 25th, 50th (median), and 75th percentiles [3, 4].\n",
    "> - .value_counts(): This method is useful for categorical data. It returns the count of each unique value in a column [3, 5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea8bfd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>362.813750</td>\n",
       "      <td>69.258750</td>\n",
       "      <td>79.001250</td>\n",
       "      <td>73.842500</td>\n",
       "      <td>72.820000</td>\n",
       "      <td>71.902500</td>\n",
       "      <td>68.277500</td>\n",
       "      <td>3.32375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>208.343798</td>\n",
       "      <td>25.534669</td>\n",
       "      <td>32.457366</td>\n",
       "      <td>31.183501</td>\n",
       "      <td>32.722294</td>\n",
       "      <td>27.828916</td>\n",
       "      <td>29.060474</td>\n",
       "      <td>1.66129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>184.750000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>49.750000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>364.500000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>539.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>5.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>721.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                #          HP      Attack     Defense     Sp. Atk     Sp. Def  \\\n",
       "count  800.000000  800.000000  800.000000  800.000000  800.000000  800.000000   \n",
       "mean   362.813750   69.258750   79.001250   73.842500   72.820000   71.902500   \n",
       "std    208.343798   25.534669   32.457366   31.183501   32.722294   27.828916   \n",
       "min      1.000000    1.000000    5.000000    5.000000   10.000000   20.000000   \n",
       "25%    184.750000   50.000000   55.000000   50.000000   49.750000   50.000000   \n",
       "50%    364.500000   65.000000   75.000000   70.000000   65.000000   70.000000   \n",
       "75%    539.250000   80.000000  100.000000   90.000000   95.000000   90.000000   \n",
       "max    721.000000  255.000000  190.000000  230.000000  194.000000  230.000000   \n",
       "\n",
       "            Speed  Generation  \n",
       "count  800.000000   800.00000  \n",
       "mean    68.277500     3.32375  \n",
       "std     29.060474     1.66129  \n",
       "min      5.000000     1.00000  \n",
       "25%     45.000000     2.00000  \n",
       "50%     65.000000     3.00000  \n",
       "75%     90.000000     5.00000  \n",
       "max    180.000000     6.00000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd74e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#    Name                   Type 1    Type 2    HP   Attack  Defense  Sp. Atk  Sp. Def  Speed  Generation  Legendary\n",
       "1    Bulbasaur              Grass     Poison    45   49      49       65       65       45     1           False        1\n",
       "479  RotomFrost Rotom       Electric  Ice       50   65      107      105      107      86     4           False        1\n",
       "494  Victini                Psychic   Fire      100  100     100      100      100      100    5           True         1\n",
       "492  ShayminSky Forme       Grass     Flying    100  103     75       120      75       127    4           True         1\n",
       "487  GiratinaOrigin Forme   Ghost     Dragon    150  120     100      120      100      90     4           True         1\n",
       "                                                                                                                       ..\n",
       "257  Blaziken               Fire      Fighting  80   120     70       110      70       80     3           False        1\n",
       "256  Combusken              Fire      Fighting  60   85      60       85       60       55     3           False        1\n",
       "254  SceptileMega Sceptile  Grass     Dragon    70   110     75       145      85       145    3           False        1\n",
       "251  Celebi                 Psychic   Grass     100  100     100      100      100      100    2           False        1\n",
       "721  Volcanion              Fire      Water     80   110     120      130      90       70     6           True         1\n",
       "Name: count, Length: 414, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079cd788",
   "metadata": {},
   "source": [
    "# For a specific Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cda1bebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HP\n",
       "60     67\n",
       "50     63\n",
       "70     57\n",
       "65     46\n",
       "80     43\n",
       "       ..\n",
       "111     1\n",
       "160     1\n",
       "81      1\n",
       "140     1\n",
       "97      1\n",
       "Name: count, Length: 94, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['HP'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0f5fae",
   "metadata": {},
   "source": [
    "# For a variable with values missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e74ea123",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type 2\n",
       "Flying      97\n",
       "Ground      35\n",
       "Poison      34\n",
       "Psychic     33\n",
       "Fighting    26\n",
       "Grass       25\n",
       "Fairy       23\n",
       "Steel       22\n",
       "Dark        20\n",
       "Dragon      18\n",
       "Water       14\n",
       "Ghost       14\n",
       "Ice         14\n",
       "Rock        14\n",
       "Fire        12\n",
       "Electric     6\n",
       "Normal       4\n",
       "Bug          3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Type 2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c909b",
   "metadata": {},
   "source": [
    "#### 4. If the dataset you're using has (a) non-numeric variables and (b) missing values in numeric variables, explain (perhaps using help from a ChatBot if needed) the discrepancies between size of the dataset given by `df.shape` and what is reported by `df.describe()` with respect to (a) the number of columns it analyzes and (b) the values it reports in the \"count\" column<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> If the dataset you're using does not have (a) non-numeric variables and (b) missing values in numeric variables (e.g., the `\"villagers.csv\"` example above has only a single numeric variable `row_n` which has no missing values), instead download and use the [https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv](https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv)\" data to answer this question  \n",
    ">\n",
    "> In (a) above, the \"columns it analyzes\" refers to the columns of the output of `df.describe()` which will only include \"numeric\" columns by default, but you can can see the names of all the columns in a dataset using `df.columns`; and, make sure `df.shape` is refering to the dataset you think it is... if you've loaded a different dataset it might not have been called `df`(!)\n",
    ">\n",
    "> **If you get any errors (for example related to column names), copy and paste them as a response to the ChatBot, and see if it can help you resove them by adding the suggested adjustments to your code and then reruning all your code to see if the changes have fixed the problem (and repeat this process as needed until the problems have been resolved).**\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a0d2a0",
   "metadata": {},
   "source": [
    "- df.shape returns the shape (dimensions) of the entire dataframe, the rows and columns in the dataset. It is returned in a tuple containing (rows, columns).\n",
    "\n",
    "- df.describe() returns only the numerical data in a dataframe in the form of a table. It provides values such as count, mean, min, Q1-3, standard deviation, and max.\n",
    "\n",
    "- a) df.shape considers all columns while df.describe() only considers numerical columns, like HP and Attack.\n",
    "\n",
    "- b) df.shape gets the count/length from the longest column, while df.describe() gets the individual lengths/counts for each numerical column. The discrepancies are shown in the Titanic Dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fde1c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df2 = pd.read_csv(url)\n",
    "print(df2.shape)\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0dc16e",
   "metadata": {},
   "source": [
    "- a) Values such as 'embarked' and 'sex' are omitted, causing there to be less columns in df.describe() vs df.size\n",
    "- b) Age and shape have different count values: **891** vs **714** , demonstrating the discrepancy caused by lower count/length in df.describe() vs df.size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8cc949",
   "metadata": {},
   "source": [
    "#### 5. Use your ChatBot session to help understand the difference between the following and then provide your own paraphrasing summarization of that difference\n",
    "\n",
    "- an \"attribute\", such as `df.shape` which does not end with `()`\n",
    "- and a \"method\", such as `df.describe()` which does end with `()` \n",
    "   \n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> The fact that a \"method\" such as `df.describe()` ends with `()` suggests that \"methods\" are essentially something that we would call a \"function\" in programming language terminology; but, without getting too technical or \"in the weeds\", it might also be worth considering that we could also contrast what the difference is between a \"function\" in a programming language versus a \"function\" in mathematics...  \n",
    "    \n",
    "</details><br><br>\n",
    "\n",
    "***Don't forget to ask for summaries of your ChatBot session(s) and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatGPT)!***<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5046ffd",
   "metadata": {},
   "source": [
    ">Here's an explanation of the difference between an \"attribute\" and a \"method\", along with insights from the sources and our previous conversation:\n",
    "\n",
    ">Attributes: Data Associated with an Object\n",
    "In programming, an attribute is a characteristic of an object, storing information about the object's state. You can think of it like a property or a variable that belongs to the object. [1, 2]\n",
    "In the context of our conversation and the sources, df.shape is an attribute of the DataFrame object df. It tells us the dimensions of the DataFrame (rows and columns) but doesn't perform any operations or calculations on the data itself. [3-7]\n",
    "Attributes are accessed without parentheses (). You simply write the object name, followed by a dot ., and the attribute name. [2]\n",
    "Methods: Actions Performed on an Object\n",
    "A method in programming is like a function that is specifically associated with a particular object. [2, 8]\n",
    "Methods perform actions or calculations using the object's data. They can modify the object or return a new object with the results. [2, 8, 9]\n",
    "You used the method df.describe() in our conversation to get a summary of your dataset. This method analyzed the numerical data within the df DataFrame and returned a new DataFrame with the summary statistics. [5, 6, 10-15]\n",
    "Methods are called with parentheses (), which can contain arguments to control their behavior.\n",
    "For example, you can use the argument inplace=True with the dropna() method to modify the DataFrame directly instead of creating a copy. [9, 16]\n",
    "Key Differences: Attributes vs. Methods\n",
    "Purpose: Attributes store information about an object, while methods act on an object's data.\n",
    "Syntax: Attributes are accessed without parentheses (), while methods are called with parentheses (), which can include arguments.\n",
    "Return Values:\n",
    "Attributes generally return a value directly related to the object's state.\n",
    "Methods may return a new object with the results of their operation, or they may modify the object in place.\n",
    "Analogy to Mathematical Functions\n",
    "You mentioned in your query that methods in programming are similar to \"functions\" in programming language terminology. [2] The sources touch upon an interesting parallel between programming \"functions\" and mathematical \"functions\". [2]\n",
    "\n",
    ">In mathematics, a function takes an input (or multiple inputs) and produces an output based on a defined rule.\n",
    "Similarly, methods in programming often take the object's data as an implicit input and return a result based on the method's defined behavior.\n",
    "Let me know if you would like more details or examples of attributes and methods, or if you have other questions!\n",
    "\n",
    "# Question 5\n",
    "- Attributes - Data associated with an object\n",
    "\n",
    "- They store values which can be returned when calling the attribute. They decribe the object.\n",
    "\n",
    "- Methods - Actions performed on an object\n",
    "\n",
    "- They manipulate values which can be both stored by the object or given by the programmer when called.\n",
    "\n",
    "\n",
    "# Summary Transcript\n",
    "\n",
    "Summary of the Conversation\n",
    "This conversation focuses on exploring a Pokemon dataset using the pandas library in Python. Here's a summary, emphasizing key points from the conversation and connecting them to relevant information from the sources you provided:\n",
    "\n",
    "Goal: Learn about the Pokemon dataset ([1, 2]) The conversation began with you seeking to understand the fundamental characteristics of a Pokemon dataset hosted on GitHub ([3]). The sources, particularly excerpts from course materials like \"STA130F24_TUT01_Sep06.md\" and \"Week-01-Data-Summarization.md,\" provide context for this exploration by emphasizing the use of Python notebooks and ChatBots for data analysis in a course setting.\n",
    "Finding the dimensions of the dataset: You asked how to determine the number of rows and columns in the dataset. The response correctly guided you to use the .shape attribute in pandas ([4-7]). The sources emphasize the importance of understanding attributes like .shape, .dtypes, and .index, which provide information about DataFrame objects without modifying them ([8, 9]).\n",
    "Understanding Observations and Variables: You then asked about the meaning of \"observations\" and \"variables\" in the context of this dataset. The response provided clear definitions: each Pokemon represents an observation (a row in the dataset), and the characteristics of each Pokemon (like Attack and Defense) are the variables (columns in the dataset) ([6, 10, 11]). This aligns with the sources' explanation that observations are typically organized as rows and variables as columns in a dataset.\n",
    "Getting Simple Summaries: You wanted to know how to generate simple summaries of the dataset's columns. The response suggested using the .describe() and .value_counts() methods ([5, 12-17]).\n",
    ".describe() is suitable for numerical data, providing statistics like mean, standard deviation, and percentiles ([4, 15, 18]).\n",
    ".value_counts() is helpful for categorical data, showing the frequency of each unique value in a column ([13, 15, 17]).\n",
    "Discrepancies in df.shape and df.describe() Output: You noticed differences between the output of df.shape and df.describe() regarding the number of columns and the values in the \"count\" column. The response clarified that df.shape considers all columns, while df.describe() focuses on numerical columns by default ([15, 19, 20]). Additionally, the \"count\" in df.describe() represents non-missing values, which might be lower than the total rows if there is missing data ([15, 19, 21, 22]).\n",
    "Attributes vs. Methods: You sought to understand the difference between attributes (like df.shape) and methods (like df.describe()). The response explained that attributes store data about an object, while methods perform actions using that data ([7, 23]).\n",
    "Attributes are accessed without parentheses.\n",
    "Methods are called with parentheses (which can include arguments).\n",
    "The conversation highlights the iterative process of data exploration. You asked progressively more specific questions, demonstrating a developing understanding of the dataset and the tools used to analyze it. The sources played a crucial role by providing background information and explanations of key concepts and techniques, such as handling missing data, data types, and the distinction between attributes and methods in Python.\n",
    "\n",
    "The conversation, however, does not explore more advanced data manipulation techniques like imputing missing values, which are mentioned as \"out of scope\" in the provided source materials ([24-29])."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea57fbf",
   "metadata": {},
   "source": [
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Continue now...?</u></summary>\n",
    "\n",
    "### Prelecture VS Postlecture HW\n",
    "    \n",
    "Feel free to work on the \"Postlecture\" HW below if you're making good progress and want to continue: in this case this is particularly reasonable as questions \"6\" and \"7\" below directly follow up and extend the \"Prelecture\" HW questions\n",
    "\n",
    "*The benefits of continue would are that (a) it might be fun to try to tackle the challenge of working through some problems without additional preparation or guidance; and (b) this is a very valable skill to be comfortable with; and (c) it will let you build experience interacting with ChatBots (and beginning to understand their strengths and limitations in this regard)... it's good to have sense of when using a ChatBot is the best way to figure something out, or if another approach (such as course provided resources or a plain old websearch for the right resourse) would be more effective*\n",
    "    \n",
    "</details>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbc0e0c",
   "metadata": {},
   "source": [
    "## \"Post-lecture\" HW [*submission along with \"Pre-lecture\" HW is due prior to next TUT*]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b28bd0",
   "metadata": {},
   "source": [
    "#### 6. The `df.describe()` method provides the 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max' summary statistics for each variable it analyzes. Give the definitions (perhaps using help from the ChatBot if needed) of each of these summary statistics<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> The answers here actually make it obvious why these can only be calculated for numeric variables in a dataset, which should help explain the answer to \"4(a)\" and \"4(b)\" above\n",
    ">   \n",
    "> Also notice that when `df.describe()` is used missing values are not explicitly removed, but `df.describe()`  provides answers anyway. Is it clear what `df.describe()` does with the data in each columns it analyzes if there is missing data in the column in question? \n",
    ">\n",
    "> The next questions addresses removing rows or columns from a dataset in order to explicitly remove the presense of any missingness in the dataset (assuming we're not going to fill in any missing data values using any missing data imputation methods, which are beyond the scope of STA130); so, the behavior of `df.describe()` hints that explicitly removing missing may not always be necessary; but, the concern, though, is that not all methods may be able to handle missing data the way `df.describe()` does...\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f23d4a",
   "metadata": {},
   "source": [
    "- **count** the amount of non null values in a column\n",
    "\n",
    "- **mean**  sum of all values in the column, divided by the count of the column $\\bar x = \\frac{1}{n} \\sum_{i=1}^{n} x_i$\n",
    "\n",
    "- **std** Standard Deviation, square root of deviance $s = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2}$.\n",
    "\n",
    "- **min** Smallest value in the column.\n",
    "\n",
    "- **25%** Quartile 1 (Q1) the datapoint where 25% of the data is below it, and 75% of data is above it, when the data is arranged in ascending order.\n",
    "\n",
    "- **50%** Median (Q2) the datapoint where 50% of the data is below it, and 50% of data is above it, when the data is arranged in ascending order. The middle data point.\n",
    "\n",
    "- **75%** Quartile 3 (Q3) the datapoint where 75% of the data is below it, and 25% of data is above it, when the data is arranged in ascending order.\n",
    "\n",
    "- **max** Largest value in the column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6a98fb",
   "metadata": {},
   "source": [
    "#### 7. Missing data can be considered \"across rows\" or \"down columns\".  Consider how `df.dropna()` or `del df['col']` should be applied to most efficiently use the available non-missing data in your dataset and briefly answer the following questions in your own words\n",
    "\n",
    "1. Provide an example of a \"use case\" in which using `df.dropna()` might be peferred over using `del df['col']`<br><br>\n",
    "    \n",
    "2. Provide an example of \"the opposite use case\" in which using `del df['col']` might be preferred over using `df.dropna()` <br><br>\n",
    "    \n",
    "3. Discuss why applying `del df['col']` before `df.dropna()` when both are used together could be important<br><br>\n",
    "    \n",
    "4. Remove all missing data from one of the datasets you're considering using some combination of `del df['col']` and/or `df.dropna()` and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset.<br><br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> Start a new ChatBot session **[but remember to first ask your ChatBot for summaries of your current session and perhaps coding results (so you can supply these in the homework as requested)]**, since your last ChatBot session has likely gotten quite long and has covered a lot of material at this point \n",
    "> - It can sometimes be helpful to reset ChatBot sessions to refocus them on the topics of inquiry without too much backlog history that might unintentionally bias things in certain directions and, of course, you can always re-introduce material from earlier conversations as it's relevant, such as for answering \"D\" based on reintroducing and updating code you made in a previous ChatBot session.  \n",
    "> \n",
    "> #### ChatBot Scope Guidance\n",
    "> \n",
    "> - This question is not interested in the general benefits of imputing missing data, or the general benefits of using `df.dropna()` and/or `del df['col']` to remove missing data, just how to most efficiently remove missing data if a user chooses to do so\n",
    "> \n",
    "> - More sophisticated analyses for \"filling in\" rather than removing missing data (as considered here) are possible (based on making assumptions about missing data and using specific imputation methods or models) but these are \"beyond the scope\" of this homework assignment so this topics can be safely ignored for now\n",
    "> \n",
    "> #### ChatBot Code Troubleshooting\n",
    "> \n",
    "> A key issue to be aware of when asking ChatBots for help with something is that they are not running and checking code for correctess, and they often intertwine written instructions with code instructions; so, BEFORE YOU RUN ANY CODE provided by a ChatBot, you should check the following\n",
    "> \n",
    "> 1. If this code changes an object or data, are you sure you want to run this code?\n",
    "> 2. Can you easily \"undo\" the results of running code (e.g., from a copy `df_saved=df.copy()` or reloading the data) if running the code doesn't do what you want?\n",
    "> 3. Is the state of the data what is expected by the code? Or have the objects been updated and changed so they're no longer what the code expects them to be? \n",
    "> \n",
    "> #### If you get any `Python` errors, copy and paste them into the ChatBot prompt and see if it can help you resove them; but, keep in mind the final point above becasue the ChatBot might not be aware of the state of your objects relative to the code it's producing...\n",
    "\n",
    "</details><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333bf554",
   "metadata": {},
   "source": [
    "1. `df.dropna()` is better used when you want to remove all the rows that are missing a datapoint, not an entire column. If only a few rows have missing datapoints, it is much better than removing an entire variable.\n",
    "\n",
    "- An example is when there is a datapoint that observations have, but not all. You lose less valuable data cutting out the few observations that don't have the datapoint, instead of removing the entire column.\n",
    "\n",
    "2. `del df['col']` is better used when you want to remove an entire column, not all the rows that are missing a datapoint. If many rows have missing datapoints, using `df.dropna()` would remove almost all your data.\n",
    "\n",
    "- An example is when the vast majority of observations do not have a datapoint under a certain variable. You lose a large amount of data using `df.dropna()`, which will delete every observation missing this value. You can instead remove the variable using `del df['col']`, that most likely isn't very valuable considering its most observations don't have a value under it.\n",
    "\n",
    "3. Using `del df['col']` and `df.dropna()` in combination allows for users to \n",
    "\n",
    "- 1. Remove all variables which would remove most observations using `df.dropna()`.\n",
    "- 2. Then remove all observations missing data the majority of other observations have.\n",
    "\n",
    "4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc3a1ed",
   "metadata": {},
   "source": [
    "- I am using the titanic dataset, as it is a better example to be manipulated than the pokemon dataset.\n",
    "# Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a34fcf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0493e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "0      man        True  NaN  Southampton    no  False  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "2    woman       False  NaN  Southampton   yes   True  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "4      man        True  NaN  Southampton    no   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "886    man        True  NaN  Southampton    no   True  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "888  woman       False  NaN  Southampton    no  False  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "890    man        True  NaN   Queenstown    no   True  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "108978d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df2['deck']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded24e9",
   "metadata": {},
   "source": [
    "# After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5dae952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "885         0       3  female  39.0      0      5  29.1250        Q   Third   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male  embark_town alive  alone  \n",
       "0      man        True  Southampton    no  False  \n",
       "1    woman       False    Cherbourg   yes  False  \n",
       "2    woman       False  Southampton   yes   True  \n",
       "3    woman       False  Southampton   yes  False  \n",
       "4      man        True  Southampton    no   True  \n",
       "..     ...         ...          ...   ...    ...  \n",
       "885  woman       False   Queenstown    no  False  \n",
       "886    man        True  Southampton    no   True  \n",
       "887  woman       False  Southampton   yes   True  \n",
       "889    man        True    Cherbourg   yes   True  \n",
       "890    man        True   Queenstown    no   True  \n",
       "\n",
       "[712 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.dropna()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d21e88c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.404494</td>\n",
       "      <td>2.240169</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0.514045</td>\n",
       "      <td>0.432584</td>\n",
       "      <td>34.567251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.491139</td>\n",
       "      <td>0.836854</td>\n",
       "      <td>14.492933</td>\n",
       "      <td>0.930692</td>\n",
       "      <td>0.854181</td>\n",
       "      <td>52.938648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.645850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  712.000000  712.000000  712.000000  712.000000  712.000000  712.000000\n",
       "mean     0.404494    2.240169   29.642093    0.514045    0.432584   34.567251\n",
       "std      0.491139    0.836854   14.492933    0.930692    0.854181   52.938648\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    1.000000   20.000000    0.000000    0.000000    8.050000\n",
       "50%      0.000000    2.000000   28.000000    0.000000    0.000000   15.645850\n",
       "75%      1.000000    3.000000   38.000000    1.000000    1.000000   33.000000\n",
       "max      1.000000    3.000000   80.000000    5.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a00d409",
   "metadata": {},
   "source": [
    "- I removed the entire 'deck' column due to numerous people missing the data.\n",
    "- I used `df.dropna` to remove the observations missing some of the information.\n",
    "- This results in a dataframe where every observation has a complete set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d258e0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#### 8. Give brief explanations in your own words for any requested answers to the questions below\n",
    "\n",
    "> This problem will guide you through exploring how to use a ChatBot to troubleshoot code using the \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\" data set \n",
    "> \n",
    "> To initialially constrain the scope of the reponses from your ChatBot, start a new ChatBot session with the following slight variation on the initial prompting approach from \"2\" above\n",
    "> - \"I am going to do some initial simple summary analyses on the titanic data set I've downloaded (https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv) which has some missing values, and I'd like to get your help understanding the code I'm using and the analysis it's performing\"\n",
    "        \n",
    "1. Use your ChatBot session to understand what `df.groupby(\"col1\")[\"col2\"].describe()` does and then demonstrate and explain this using a different example from the \"titanic\" data set other than what the ChatBot automatically provide for you\n",
    "    \n",
    "> If needed, you can help guide the ChatBot by showing it the code you've used to download the data **AND provide it with the names of the columns** using either a summary of the data with `df.describe()` or just `df.columns` as demonstrated [here](../CHATLOG/COP/00017_copilot_groupby.md)\n",
    "    \n",
    "2. Assuming you've not yet removed missing values in the manner of question \"7\" above, `df.describe()` would have different values in the `count` value for different data columns depending on the missingness present in the original data.  Why do these capture something fundamentally different from the values in the `count` that result from doing something like `df.groupby(\"col1\")[\"col2\"].describe()`?\n",
    "\n",
    "> Questions \"4\" and \"6\" above address how missing values are handled by `df.describe()` (which is reflected in the `count` output of this method); but, `count` in conjunction with `group_by` has another primary function that's more important than addressing missing values (although missing data could still play a role here).\n",
    "\n",
    "3. Intentionally introduce the following errors into your code and report your opinion as to whether it's easier to (a) work in a ChatBot session to fix the errors, or (b) use google to search for and fix errors: first share the errors you get in the ChatBot session and see if you can work with ChatBot to troubleshoot and fix the coding errors, and then see if you think a google search for the error provides the necessary toubleshooting help more quickly than ChatGPT<br><br>\n",
    "    \n",
    "    1. Forget to include `import pandas as pd` in your code \n",
    "       <br> \n",
    "       Use Kernel->Restart from the notebook menu to restart the jupyter notebook session unload imported libraries and start over so you can create this error\n",
    "       <br><br>\n",
    "       When python has an error, it sometimes provides a lot of \"stack trace\" output, but that's not usually very important for troubleshooting. For this problem for example, all you need to share with ChatGPT or search on google is `\"NameError: name 'pd' is not defined\"`<br><br>\n",
    "\n",
    "    2. Mistype \"titanic.csv\" as \"titanics.csv\"\n",
    "       <br> \n",
    "       If ChatBot troubleshooting is based on downloading the file, just replace the whole url with \"titanics.csv\" and try to troubleshoot the subsequent `FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv'` (assuming the file is indeed not present)\n",
    "       <br><br>\n",
    "       Explore introducing typos into a couple other parts of the url and note the slightly different errors this produces<br><br>\n",
    "      \n",
    "    3. Try to use a dataframe before it's been assigned into the variable\n",
    "       <br> \n",
    "       You can simulate this by just misnaming the variable. For example, if you should write `df.groupby(\"col1\")[\"col2\"].describe()` based on how you loaded the data, then instead write `DF.groupby(\"col1\")[\"col2\"].describe()`\n",
    "       <br><br>\n",
    "       Make sure you've fixed your file name so that's not the error any more<br><br>\n",
    "        \n",
    "    4. Forget one of the parentheses somewhere the code\n",
    "       <br>\n",
    "       For example, if the code should be `pd.read_csv(url)` the change it to `pd.read_csv(url`<br><br>\n",
    "        \n",
    "    5. Mistype one of the names of the chained functions with the code \n",
    "       <br>\n",
    "       For example, try something like `df.group_by(\"col1\")[\"col2\"].describe()` and `df.groupby(\"col1\")[\"col2\"].describle()`<br><br>\n",
    "        \n",
    "    6. Use a column name that's not in your data for the `groupby` and column selection \n",
    "       <br>\n",
    "       For example, try capitalizing the columns for example replacing \"sex\" with \"Sex\" in `titanic_df.groupby(\"sex\")[\"age\"].describe()`, and then instead introducing the same error of \"age\"<br><br>\n",
    "        \n",
    "    7. Forget to put the column name as a string in quotes for the `groupby` and column selection, and see if the ChatBot and google are still as helpful as they were for the previous question\n",
    "       <br>\n",
    "       For example, something like `titanic_df.groupby(sex)[\"age\"].describe()`, and then `titanic_df.groupby(\"sex\")[age].describe()`\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ee41f9",
   "metadata": {},
   "source": [
    "# 8.1.\n",
    "\n",
    "> Understanding in Pandas with the Titanic Dataset<br>\n",
    "Let's break down what each part of the code df.groupby(\"col1\")[\"col2\"].describe() does, and then we'll illustrate its application using the Titanic dataset you're working with.<br>●\n",
    "df.groupby(\"col1\"): This line of code takes your DataFrame df and groups the rows based on the unique values present in the column named \"col1\". Imagine splitting your Titanic dataset into separate tables based on passenger class ('First', 'Second', 'Third') - that's what grouping achieves.<br>●\n",
    "[\"col2\"]: After grouping, this part focuses specifically on the column named \"col2\". You're now working with subsets of data from \"col2\" corresponding to each unique value in \"col1\".<br>●\n",
    ".describe(): Finally, .describe() calculates a set of summary statistics for the data in \"col2\" within each group created in the previous step. These statistics typically include:○\n",
    "Count: Number of non-null values.<br>○\n",
    "Mean: The average value.<br>○\n",
    "Standard Deviation: A measure of data spread.<br>○\n",
    "Minimum: The smallest value.<br>○\n",
    "25th Percentile (Q1): The value below which 25% of the data falls.<br>○\n",
    "Median (50th Percentile/Q2): The middle value.<br>○\n",
    "75th Percentile (Q3): The value below which 75% of the data falls.<br>○\n",
    "Maximum: The largest value.\n",
    "Titanic Dataset Example\n",
    "Let's say you want to see how the age of passengers (\"age\") differs across different passenger classes (\"pclass\") in the Titanic dataset. You can use the following code:\n",
    "import pandas as pd\n",
    "\n",
    "> # Assuming you have already loaded the Titanic data into a DataFrame called 'titanic_df'\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic_df = pd.read_csv(url)\n",
    "\n",
    ">titanic_df.groupby(\"pclass\")[\"age\"].describe() \n",
    "This code will give you a table where each row represents a passenger class, and the columns show the descriptive statistics (count, mean, std, etc.) of age for passengers within that class.\n",
    "Key Points<br>●\n",
    "Missing Values: The .describe() method automatically excludes missing values when calculating the statistics. If there are missing values in the grouping column (\"pclass\" in our example), a separate group will be created for them.<br>●\n",
    "Data Types: This approach is most meaningful when \"col2\" (in this case, \"age\") is a numerical column, as you are calculating numerical summaries.\n",
    "Let me know if you would like to explore another example or have further questions!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e346cb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>259.0</td>\n",
       "      <td>0.752896</td>\n",
       "      <td>0.432163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>453.0</td>\n",
       "      <td>0.205298</td>\n",
       "      <td>0.404366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count      mean       std  min  25%  50%  75%  max\n",
       "sex                                                       \n",
       "female  259.0  0.752896  0.432163  0.0  1.0  1.0  1.0  1.0\n",
       "male    453.0  0.205298  0.404366  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby(\"sex\")[\"survived\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f763f589",
   "metadata": {},
   "source": [
    "- Sorts the data by value 1 (in this example, sex) and specifically returns the data in value 2 (in this example, survived).\n",
    "- It then shows the summary statistics using `df.describe()`\n",
    "\n",
    "- The summary statistics are more evidently shown in the chatbot's example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47f50d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184.0</td>\n",
       "      <td>38.105543</td>\n",
       "      <td>14.778904</td>\n",
       "      <td>0.92</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173.0</td>\n",
       "      <td>29.877630</td>\n",
       "      <td>14.001077</td>\n",
       "      <td>0.67</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355.0</td>\n",
       "      <td>25.140620</td>\n",
       "      <td>12.495398</td>\n",
       "      <td>0.42</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "pclass                                                           \n",
       "1       184.0  38.105543  14.778904  0.92  27.0  37.0  49.0  80.0\n",
       "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
       "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby(\"pclass\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c6131",
   "metadata": {},
   "source": [
    "# 8.2.\n",
    "\n",
    "- `df.describe()` would give me the count of each different numerical varible, while 'df.groupby(\"col1\")[\"col2\"].describe()' gives me the count of each different value within a variable (col1 in this example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43983816",
   "metadata": {},
   "source": [
    "# 8.3.\n",
    "<br>\n",
    "\n",
    "# a) -> chatbot response<br>\n",
    "\n",
    "# b) -> google search\n",
    "\n",
    "# A.\n",
    "\n",
    "### a) \n",
    "This error message indicates that you are trying to use the abbreviation **'pd'** before defining it. In the context of data analysis using Python, 'pd' is commonly used as an alias for the **pandas library**. \n",
    "\n",
    "*   This library needs to be imported into your Python environment before you can use its functions or objects. You can import the pandas library and assign it the alias \"pd\" using the following code:\n",
    "\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    ```\n",
    "*   This import statement should be placed at the **beginning** of your Python code, before any attempts to use pandas functions.\n",
    "\n",
    "For example, if you intend to read a CSV file named \"data.csv\" and store it in a DataFrame called `df`, you would use the following code:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "1.  **`import pandas as pd`**: This line imports the pandas library and assigns it the alias 'pd'. This allows you to refer to pandas functions and objects using 'pd' instead of writing out 'pandas' each time.\n",
    "2.  **`df = pd.read_csv(\"data.csv\")`**: This line uses the `read_csv()` function from the pandas library (now accessible as `pd`) to read the contents of \"data.csv\" into a pandas DataFrame. The resulting DataFrame is then assigned to the variable `df`.\n",
    "\n",
    "**Key Points**\n",
    "\n",
    "*   **Importing Libraries**: Importing libraries is crucial in Python to access specialized functions.  Always ensure that you import the necessary libraries before using their components.\n",
    "*   **Aliases**: Using aliases like 'pd' for 'pandas' is a common practice to write more concise code.  However, make sure to define the alias (using `import ... as ...`) before using it.\n",
    "*   **Order of Execution**: Python code executes line by line. Keep in mind that you need to define or import elements before using them in subsequent lines of code.\n",
    "*   **Troubleshooting**: When you encounter errors like \"NameError: name '...' is not defined\", it usually means Python cannot find the specified name. Double-check your code for typos and ensure that you have imported the necessary libraries or defined the variables correctly.\n",
    "\n",
    "Remember to always include the import statement (`import pandas as pd`) at the beginning of your code to avoid encountering this error when working with pandas.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### b)\n",
    "> This error usually occurs when you import the python library pandas, but fail to give it the alias of pd when importing it.\n",
    "\n",
    "## Consensus \n",
    "\n",
    "The chatbot gives a lot more information, including the correct line of code needed. A search gave a much shorter, but more concise answer, but it does not include the line of code needed.\n",
    "\n",
    "The chatbot gave a much more helpful answer as it described everything you need to do in detail, including the code needed. \n",
    "\n",
    "# B.\n",
    "\n",
    "### a)\n",
    "\n",
    "Let's troubleshoot this \"FileNotFoundError\".\n",
    "\n",
    "*   This error message typically means that Python cannot locate the file you're trying to access. Specifically, the error message \"FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv'\" means that Python is looking for a file named \"titanics.csv\", but it's not finding it in the directory where it's being instructed to look.  \n",
    "*   In the context of the provided sources on data summarization and working with pandas in Python, you likely encountered this error when trying to load a dataset using `pd.read_csv()`. For instance, if you ran code like this, you would get an error if the file 'titanics.csv' was not in the current working directory:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('titanics.csv')\n",
    "```\n",
    "\n",
    "**Here's a breakdown of how to address this error:**\n",
    "\n",
    "*   **Verify the File Name:** The most common cause of this error is a simple typo in the file name. Double-check that you have typed the file name correctly in your code. Pay close attention to capitalization and any extra characters. In this specific case, the file name should be \"titanic.csv\", not \"titanics.csv\", so make sure you haven't added an extra \"s\".\n",
    "*   **Check the File Path:** If the file name is correct, ensure that the file is located in the directory from which you're running your Python script. The `pd.read_csv()` function, by default, looks for the file in the current working directory. If the file is in a different directory, you need to provide the full path to the file. For example, if the file 'titanic.csv' is located in the 'Downloads' folder on your computer, you might try something like this, assuming the rest of the path on your computer is the same as the example:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/yourusername/Downloads/titanic.csv')\n",
    "```\n",
    "\n",
    "*   If you're working with a file located in a subdirectory relative to your current directory, you can use relative paths. For instance:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/titanic.csv') \n",
    "```\n",
    "\n",
    "*   **URLs and Raw Data:**  If you are trying to load a dataset directly from a URL, as often discussed in the sources, remember that you need the direct link to the raw CSV file. A common mistake is using the URL of a webpage that displays the CSV data instead of the raw data's URL. \n",
    "\n",
    "    *   **Example:** In the sources, they point out that a link like this is not a raw CSV file, but rather a webpage displaying a CSV: https://github.com/mwaskom/seaborn-data/blob/master/titanic.csv. To load data from this source, you would use the corresponding raw CSV link: https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv. \n",
    "\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "\n",
    "    url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv' \n",
    "    df = pd.read_csv(url)\n",
    "    ```\n",
    "*   **Confirm File Existence:** If you've checked the file name and path, and you're still encountering the error, double-check that the file actually exists in the specified location. It's possible the file was accidentally deleted or saved to a different location.\n",
    "*   **Restart Kernel  (if applicable):** If you're working in a Jupyter Notebook environment, restarting the kernel can sometimes resolve file path issues. You can do this by going to \"Kernel\" -> \"Restart\" in the Jupyter Notebook menu.\n",
    "\n",
    "Let me know if you've verified all of these steps, and we can explore further troubleshooting if needed.\n",
    "\n",
    "\n",
    "### b)\n",
    "\n",
    "> Why does Filenotfounderror Errno 2 No Such File Or Directory Occur?\n",
    "Below, are the reasons of occurring Filenotfounderror Errno 2 No Such File Or Directory in Python:\n",
    "\n",
    "> Incorrect File Path\n",
    "\n",
    "\n",
    "## Consensus \n",
    "\n",
    "Like before the chatbot gives a lot more information, including the correct line of code needed. The chatbot also outlined many different scenarios in great detail. A search gave a much shorter, but more concise answer, but it does not include the line of code needed. The article I found also did not touch upon links, only files on your computer.\n",
    "\n",
    "Similar to before, the chatbot gave a much more helpful answer as it described everything you need to do in detail, including the code needed. \n",
    "\n",
    "\n",
    "# C.\n",
    "\n",
    "### a)\n",
    "\n",
    "Let's break down this \"NameError\" and how to fix it.\n",
    "\n",
    "*   The error message \"NameError: name 'DF' is not defined\" means that Python cannot find anything associated with the name 'DF'. \n",
    "*   In your Python code, you might be trying to use 'DF' as a variable name, but Python is case-sensitive, meaning that 'DF' and 'df' are treated as different entities. \n",
    "\n",
    "**Recalling Previous Conversations**\n",
    "\n",
    "*   Looking back at our conversation history about the \"NameError: name 'pd' is not defined\", you encountered a similar issue. In that case, the problem was that you were trying to use the abbreviation 'pd' (for the 'pandas' library) before importing and defining it. \n",
    "*   The current error with 'DF' might stem from a similar oversight—you might be trying to use 'DF' to refer to a pandas DataFrame before assigning a DataFrame to that specific variable name.\n",
    "\n",
    "**Here's what you can do:**\n",
    "\n",
    "1.  **Check for typos and case sensitivity**: Make sure that you are using the correct capitalization for 'DF'. If you intend to refer to a DataFrame named 'df' (lowercase), using 'DF' will cause this error.\n",
    "2.  **Make sure 'DF' is defined**: Before you try to use 'DF', you need to make sure it's been defined by assigning a value to it. If you haven't created a DataFrame and assigned it to the variable 'DF', Python won't know what you're referring to. You might have named your DataFrame something else, like 'titanic\\_df' or 'data'. \n",
    "\n",
    "**Example using `pd.read_csv()`:**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "DF = pd.read_csv(url)\n",
    "\n",
    "print(DF.head()) \n",
    "```\n",
    "\n",
    "*   In this example, we first import pandas as 'pd', define a URL, and then we read the CSV file from that URL into a DataFrame. Crucially, **we assign the DataFrame to the variable named `DF`**.\n",
    "*   If you were to try to use `DF` before this line of code, or if you had used a different variable name, you would get the \"NameError: name 'DF' is not defined\". \n",
    "\n",
    "**If you are still facing issues, please provide the following, and I can give more specific guidance:**\n",
    "\n",
    "*   The relevant snippet of your code where this error occurs. \n",
    "*   Any additional context about what you are trying to achieve with your code. \n",
    "\n",
    "Let's resolve this error and get your code running smoothly!\n",
    "\n",
    "\n",
    "### b) \n",
    "> The df name error usually occurs when you try to use a DataFrame object df before it has been defined. This is a common mistake when working with Pandas (or any Python script, really), which uses the DataFrame object to store data in two-dimensional size-mutable, potentially heterogeneous tabular form.\n",
    "\n",
    "## Consensus\n",
    "\n",
    "Compared to search, the chatbot gave a much easier to follow answer. The chatbot mentions the mistyping of 'df' unlike which just states the dataframe is undefined. The chatbot explains how to correct the issue in this situation, unlike the search.\n",
    "\n",
    "The chatbot gave a much better answer compared to the search; it has more detail and gives a more direct answer.\n",
    "\n",
    "# D.\n",
    "### a)\n",
    "### SyntaxError: '(' was never closed\n",
    "\n",
    "The error message **\"SyntaxError: '(' was never closed\"** means that you have an opening parenthesis `(` in your code that is not properly closed with a closing parenthesis `)`. In Python, parentheses are used to group expressions and to define function arguments.\n",
    "\n",
    "**Explanation of the Error**\n",
    "\n",
    "*   **Incomplete Expression:** The `SyntaxError` arises because Python encounters an opening parenthesis without a corresponding closing parenthesis, leaving the expression incomplete.\n",
    "*   **Function Arguments:** In Python, function arguments are enclosed in parentheses. If you forget a closing parenthesis after defining the function arguments, the code will not be syntactically correct. \n",
    "\n",
    "**How to Fix the Error**\n",
    "\n",
    "To fix the error, you need to **locate the missing closing parenthesis `)`** in your code. You might be missing a parenthesis for a function call, or there might be a misplaced parenthesis within a larger expression. Here's an example:\n",
    "\n",
    "```python\n",
    "# Incorrect code: missing closing parenthesis\n",
    "df = pd.read_csv(url \n",
    "\n",
    "# Correct code: closing parenthesis added\n",
    "df = pd.read_csv(url)\n",
    "```\n",
    "\n",
    "**Additional Considerations**\n",
    "\n",
    "*   **Check Indentation:** Python relies on indentation for code structure. Make sure the indentation in your code is correct, as a misplaced indentation can sometimes lead to missing parentheses.\n",
    "*   **Use a Code Editor:** Many code editors come with syntax highlighting, which can help you identify missing parentheses and other syntax errors visually.\n",
    "\n",
    "**Example from the Sources**\n",
    "\n",
    "*   **** The sources demonstrate the correct usage of `pd.read_csv()` with the closing parenthesis present in all examples.\n",
    "\n",
    "**Based on your previous conversations, it is likely that you are encountering this error while trying to import data from a URL.** \n",
    "\n",
    "Let me know if you can provide the code snippet where this error occurs, and I can help you troubleshoot it further! \n",
    "\n",
    "### b)\n",
    "As simple as this error is, I couldn't find any results about closing the ending bracket in a method. But the error message is very easy to read.\n",
    ">     df = pd.read_csv(url \n",
    "                    ^\n",
    "SyntaxError: '(' was never closed\n",
    "\n",
    "\n",
    "\n",
    "## Consensus\n",
    "\n",
    "The chatbot gave a much better answer than searching the error up. The chatbot even went so far as to showing the correct and incorrect code side by side:\n",
    "\n",
    "```python\n",
    "# Incorrect code: missing closing parenthesis\n",
    "df = pd.read_csv(url \n",
    "\n",
    "# Correct code: closing parenthesis added\n",
    "df = pd.read_csv(url)\n",
    "```\n",
    "The search only gave information about corrupted data and `.spec` files.\n",
    "\n",
    "The chatbot gave a much better answer compared to the search, which gave nothing of use.\n",
    "\n",
    "\n",
    "# E.\n",
    "\n",
    "### a)\n",
    "\n",
    "\n",
    "Let's work through this \"AttributeError\" and figure out how to correct it.\n",
    "\n",
    "*   The error message **\"AttributeError: 'SeriesGroupBy' object has no attribute 'desscribe'\"** means that you are trying to access an attribute or method called 'desscribe' on a Python object of type 'SeriesGroupBy', but this type of object does not have any attribute or method with that name.  \n",
    "\n",
    "*   More specifically, the 'desscribe' in the error message is a typo, and the correct spelling is 'describe'.\n",
    "\n",
    "*   It's also likely that you encountered this error while working with the **pandas** library in Python because the `.describe()` method is a common way to get descriptive statistics for a pandas DataFrame or Series.\n",
    "\n",
    "**Explanation and Solution**\n",
    "\n",
    "1.  **Typo in Method Name:** The most likely reason for this error is a simple typo. The correct method name in pandas for getting descriptive statistics is `.describe()`, not `.desscribe()`. Make sure to correct this typo in your code.\n",
    "\n",
    "2.  **Understanding 'SeriesGroupBy' Objects:** In pandas, a 'SeriesGroupBy' object is created when you use the `.groupby()` method on a DataFrame and then select a single column. For instance:\n",
    "\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.DataFrame({'A': ['a', 'b', 'a', 'b'], 'B':})\n",
    "    grouped = df.groupby('A')['B'] \n",
    "    print(type(grouped))  # This will output: <class 'pandas.core.groupby.generic.SeriesGroupBy'>\n",
    "    ```\n",
    "    The variable `grouped` in this example is a 'SeriesGroupBy' object.\n",
    "\n",
    "3.  **Applying `.describe()` to  'SeriesGroupBy' Objects:** You can apply the `.describe()` method directly to a 'SeriesGroupBy' object to get descriptive statistics for each group:\n",
    "\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.DataFrame({'A': ['a', 'b', 'a', 'b'], 'B':})\n",
    "    grouped = df.groupby('A')['B']\n",
    "    grouped.describe()  \n",
    "    ```\n",
    "\n",
    "**Recalling the Sources**\n",
    "\n",
    "*   **Week 01 Data Summarization:** In the \"Grouping and Aggregation\" section of the source titled \"Excerpts from 'Week-01-Data-Summarization.md'\", it's mentioned that **\"When you use `df.groupby(\"col1\")[\"col2\"].describe()` you're doing all of these at once\"**. This directly addresses the context of your error message and emphasizes that `.describe()` is a valid method to call on a 'SeriesGroupBy' object.\n",
    "\n",
    "*   **TUT/HW Topics:** Similarly, the \"Grouping and Aggregation\" section of the source titled \"Excerpts from '00-STA130-Course-Wiki-Textbook.md'\" includes `df.groupby(\"col1\")[\"col2\"].describe()` as an example.\n",
    "\n",
    "**To summarize:**\n",
    "\n",
    "*   Carefully review your code and correct the typo from 'desscribe' to 'describe'.\n",
    "*   Ensure that you are applying the `.describe()` method directly to your 'SeriesGroupBy' object, which is created after you perform a `groupby` operation.\n",
    "\n",
    "If you are still facing issues after correcting these points, please provide the relevant code snippet and a description of what you are trying to achieve, and I'll be happy to provide more specific guidance. \n",
    "\n",
    "\n",
    "### b)\n",
    "\n",
    "> How do I fix an object has no attribute error in Python?\n",
    "<br>To fix this error:\n",
    "<br>Check for Typos: Ensure that the attribute name is spelled correctly.\n",
    "\n",
    "## Consensus\n",
    "\n",
    "The chatbot's answer was much longer but showed the correction and cited sources. The search just explained that there is a typo, not what the typo is.\n",
    "\n",
    "The chatbot a better and more in depth answer versus the search.\n",
    "\n",
    "# F.\n",
    "\n",
    "### a)\n",
    "\n",
    "Let's break down this error, considering it appears in the context of our conversation about the Python programming language and the pandas library:\n",
    "\n",
    "*   **KeyError:** In Python, a \"KeyError\" usually occurs when you try to access a dictionary key that doesn't exist. Since pandas DataFrames are built on top of dictionaries, this error can also happen when working with DataFrames. \n",
    "\n",
    "*   **'Sex'**: This part of the error message tells us that the key 'Sex' is the source of the problem. You are likely trying to access a column named 'Sex' in your DataFrame, but that column might not exist, or it might be named differently (remember Python is case-sensitive!).\n",
    "\n",
    "**Considering our conversation history:**\n",
    "\n",
    "*   You were working on troubleshooting coding errors, including those related to file paths and typos. \n",
    "*   The error \"KeyError: 'Sex'\" often arises from typos in column names, especially when copying and pasting code or working with datasets that have case-sensitive column names. \n",
    "\n",
    "**Here's a breakdown of how to resolve a \"KeyError: 'Sex'\" in the context of working with pandas DataFrames:**\n",
    "\n",
    "1.  **Verify the Column Name (Case Sensitivity):**  Carefully check the names of the columns in your DataFrame. Ensure that 'Sex' is the exact name used in your DataFrame. You can print out the column names using `df.columns`.\n",
    "\n",
    "2.  **Check for Typos:**  Double-check the spelling of 'Sex' everywhere you use it in your code. Make sure it's consistent and correct, especially in the code that's causing the error.\n",
    "\n",
    "3.  **Data Loading:** If the error occurs when you first load the data, the column might not be named 'Sex' in the original source. Inspect your data file (e.g., CSV) or the documentation of the dataset to confirm the actual column name. It might be 'sex', 'gender', or something else. If necessary, use the `names` parameter of `pd.read_csv()` to specify custom column names when loading your data (See \"Function/Method Arguments\" from the sources for more on this).\n",
    "\n",
    "4.  **Previous Operations:** If the 'Sex' column was present initially but you're getting this error later, review any operations you've performed on the DataFrame. It's possible that an operation like dropping columns, renaming columns, or creating new DataFrames might have unintentionally removed or modified the column.\n",
    "\n",
    "**Example Using Code:**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'titanic.csv' is in the correct location \n",
    "df = pd.read_csv('titanic.csv') \n",
    "\n",
    "# Check if 'Sex' exists in the columns\n",
    "if 'Sex' in df.columns:\n",
    "    print(df.groupby('Sex')['age'].describe())\n",
    "else:\n",
    "    print(\"Column 'Sex' not found in DataFrame. Available columns:\", df.columns) \n",
    "```\n",
    "\n",
    "If, after checking these points, you're still encountering the error, please provide the following, and we can troubleshoot further:\n",
    "\n",
    "*   The relevant code snippet where the error occurs.\n",
    "*   The output of `df.columns` to see the available columns.\n",
    "*   A brief description of what you're trying to achieve in your code. \n",
    "\n",
    "Let's break down this \"KeyError\" and figure out what it means in the context of our conversation about coding in Python using the pandas library:\n",
    "\n",
    "*   **KeyError:** This error typically occurs when you're working with dictionaries in Python and try to access a key that does not exist. Since pandas DataFrames share similarities with dictionaries in how they organize data, \"KeyError\" messages can also come up when you are working with pandas DataFrames. \n",
    "\n",
    "*   **'Column not found: Age'**:  This specific error message tells us that you're trying to work with a column named 'Age' in your DataFrame, but Python cannot find a column with that exact name. \n",
    "\n",
    "**Reflecting on our Previous Conversations**\n",
    "\n",
    "*   Throughout our conversation about debugging code, we have encountered similar issues with typos and case sensitivity. For example, we addressed errors like \"NameError: name 'DF' is not defined\" and \"AttributeError: 'SeriesGroupBy' object has no attribute 'desscribe'\", both of which stemmed from typos.\n",
    "\n",
    "*   Given this pattern of typos, it's highly probable that the \"KeyError: 'Column not found: Age'\" is also due to a typo or a misunderstanding of the actual column name in your data. \n",
    "\n",
    "**Here's a breakdown of how to address this \"KeyError\", drawing on the sources provided:**\n",
    "\n",
    "1.  **Case Sensitivity:** Remember that Python is case-sensitive, so 'Age', 'age', and 'AGE' would all be treated as different column names. **Carefully review your code and the DataFrame's column names to ensure that the capitalization of 'Age' is consistent.** You can use `df.columns` to print a list of the available column names in your DataFrame.\n",
    "\n",
    "2.  **Typos in Column Names:** Double-check for any typos in the column name 'Age' in your code, especially if you've copied and pasted it from another source or if you are working with a dataset that you constructed yourself. **Even a single incorrect character can lead to a \"KeyError\".**\n",
    "\n",
    "3.  **Confirm Column Name During Data Loading:** If you encounter the error immediately when trying to load the data, the issue might originate from the data source itself. Open the source file (e.g., a CSV file) or consult the dataset documentation to **verify the exact name of the column**. It might be named differently, such as 'age', 'Age\\_of\\_passenger', or a variation thereof. You may need to adjust your code or use the `names` parameter in `pd.read_csv()` to specify the correct column names during import. The sources provide guidance on how to do this in the section \"Function/Method Arguments\".\n",
    "\n",
    "4.  **Column Modification After Loading:** If you could use the 'Age' column previously but are encountering the error later in your code, review the operations performed on your DataFrame after loading the data. **It's possible that actions such as dropping columns, renaming columns, or filtering rows might have led to the unintentional removal or alteration of the 'Age' column.**\n",
    "\n",
    "**It's important to carefully examine these possibilities and correct any discrepancies to resolve the error.** If you've checked these points and are still facing difficulties, please share the following so I can provide further assistance:\n",
    "\n",
    "*   The relevant snippet of code where the error happens.\n",
    "*   The output of `df.columns` to show the available column names in your DataFrame.\n",
    "*   A concise description of what you're aiming to accomplish with the code. \n",
    "\n",
    "\n",
    "### b)\n",
    "\n",
    "> A KeyError generally means the key doesn't exist. So, are you sure the `key name here` key exists?\n",
    "\n",
    "## Consensus\n",
    "\n",
    "The chatbot was not only able to solve the error, it was able to figure out that the majority of the previous errors are caused by typos. The search gives a more general answer, and does explain that a typo is the error.\n",
    "\n",
    "The chatbot gave a better answer versus the search in this scenario, and unlike the search, it told me how to fix future errors like this.\n",
    "\n",
    "# G.\n",
    "\n",
    "### a)\n",
    "\n",
    "### Understanding \"NameError: name 'age' is not defined\" \n",
    "\n",
    "This error message signals that Python encountered the name 'age' in your code but couldn't find a variable or object associated with that specific name. Let's break it down:\n",
    "\n",
    "*   **NameError:** This error type usually arises when you try to use a variable or object before it has been defined or assigned a value. \n",
    "\n",
    "*   **'age' is not defined:** This part tells you that the name causing the problem is 'age'.  It indicates that Python doesn't recognize 'age' as a defined variable, function, class, module, or any other named entity within the current scope of your code.\n",
    "\n",
    "**Reflecting on Our Conversation and Connecting to the Sources**\n",
    "\n",
    "*   Throughout our conversation, we've seen a pattern of errors related to typos and case sensitivity, such as \"AttributeError: 'SeriesGroupBy' object has no attribute 'desscribe'\", \"KeyError: 'Sex'\", and \"KeyError: 'Column not found: Age'\". \n",
    "\n",
    "*   **The sources, particularly the sections discussing \"KeyError\" messages and the importance of case sensitivity in Python (see our conversation about 'Sex' and 'Age' column errors), highlight how easily these errors can occur.** \n",
    "\n",
    "**Here's How to Troubleshoot, Informed by the Sources:**\n",
    "\n",
    "1.  **Case Sensitivity:**  Python is case-sensitive. **This means 'age', 'Age', and 'AGE' would all be considered distinct names.**  Carefully check the spelling and capitalization of 'age' throughout your code. Make sure it's used consistently, especially if you're referring to a DataFrame column (which we've discussed extensively in the context of previous errors). You can use `df.columns` to print a list of your DataFrame's columns to ensure the name is exactly as it appears in your data.\n",
    "\n",
    "2.  **Variable Definition:** **Before you can use 'age', you need to define it.** If 'age' is meant to be a variable, make sure you've assigned it a value before the line of code causing the error.  For example:\n",
    "    ```python\n",
    "    age = 25 \n",
    "    print(age) \n",
    "    ```\n",
    "\n",
    "3.  **Column Access:**  If 'age' refers to a column in your DataFrame, **ensure you're accessing it correctly using square brackets `[]` and the correct DataFrame name.** Example:\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.DataFrame({'age': }) \n",
    "    print(df['age'])  \n",
    "    ```\n",
    "\n",
    "4.  **Scope:** In Python, variables have scopes. If you've defined 'age' inside a function, loop, or conditional statement, you can't use it directly outside that block of code.  **Make sure 'age' is defined within the same scope where you're trying to use it.**\n",
    "\n",
    "5.  **Reserved Words:** 'age' is not a Python reserved word, but it's good practice to avoid using reserved words as variable names (e.g., `for`, `while`, `if`, `else`, `def`, etc.) to prevent conflicts.\n",
    "\n",
    "**Drawing on our experience with the \"KeyError\" examples, where we looked for potential issues during data loading and column modifications, it's essential to consider if similar scenarios apply to the 'age' name. **\n",
    "\n",
    "If you've reviewed these points and are still having trouble, please provide the following, and we can troubleshoot further:\n",
    "\n",
    "*   The relevant code snippet where the \"NameError\" occurs.\n",
    "*   If applicable, the output of `df.columns` to confirm column names in your DataFrame.\n",
    "*   A brief description of what you intend to achieve with the code. \n",
    "\n",
    "Let's troubleshoot the \"NameError: name 'sex' is not defined\" error, taking into account our prior conversations and the information available in the sources.\n",
    "\n",
    "*   **NameError:** This error message typically means Python encountered the name 'sex' in your code but couldn't locate a variable, function, or any other object associated with that exact name within the current scope.\n",
    "\n",
    "*   **'sex' is not defined:** This part explicitly tells us that the name 'sex' is the issue. Python doesn't recognize 'sex' as a defined entity in your code. \n",
    "\n",
    "### Drawing Parallels from Our Conversation History\n",
    "\n",
    "We've addressed similar \"KeyError\" and \"NameError\" messages in our previous exchanges, pointing to a recurring theme of potential typos and case sensitivity issues. For instance:\n",
    "\n",
    "*   **\"KeyError: 'Sex'\"**: We discussed that Python is case-sensitive and that accessing a column named 'Sex' wouldn't work if the actual column name was 'sex'.\n",
    "*   **\"KeyError: 'Column not found: Age'\"**: Similar to the 'Sex' example, we explored the possibility of the column name being 'age' instead of 'Age'.\n",
    "*   **\"NameError: name 'age' is not defined\"**: We determined that this error might arise if 'age' was intended as a variable but wasn't assigned a value or if it was used before its definition.\n",
    "\n",
    "### Troubleshooting Steps, Guided by the Sources\n",
    "\n",
    "1.  **Case Sensitivity (Crucial, Based on Past Errors):** Python distinguishes between uppercase and lowercase letters. This means 'sex', 'Sex', and 'SEX' are all different. **Thoroughly examine your code and DataFrame columns (using `df.columns`) to guarantee the capitalization of 'sex' is consistent.**  This is especially critical if you are trying to access a DataFrame column, as inconsistencies in case have been the root of past errors.\n",
    "\n",
    "2.  **Column Existence:** If 'sex' refers to a DataFrame column, **double-check if that column actually exists in your DataFrame**. Print the column names using `df.columns` to confirm. **This directly relates to our discussions about \"KeyError\" messages where the column might not exist or could be named differently in the original dataset.**\n",
    "\n",
    "3.  **Typos (A Common Culprit):** Carefully review your code for any typos in the name 'sex', especially if you copied it from elsewhere.  **As we've seen, even a small error can trigger a \"NameError\".**\n",
    "\n",
    "4.  **Variable Definition:** If you intend 'sex' to be a variable, ensure you've assigned it a value before the line of code causing the error. For instance:\n",
    "    ```python\n",
    "    sex = \"female\"  # Or any other relevant value\n",
    "    print(sex)\n",
    "    ```\n",
    "\n",
    "5.  **Column Access (Using Square Brackets):** If 'sex' represents a DataFrame column, make sure you're accessing it correctly:\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "\n",
    "    data = {'sex': ['male', 'female', 'female']}\n",
    "    df = pd.DataFrame(data)\n",
    "    print(df['sex']) \n",
    "    ```\n",
    "\n",
    "6.  **Scope (Where is 'sex' Defined?):**  If you defined 'sex' inside a function, loop, or conditional statement, you cannot use it directly outside that code block.  Ensure 'sex' is defined within the same scope where you're trying to use it.\n",
    "\n",
    "7.  **Reserved Words:**  While 'sex' is not a Python reserved word, it's advisable to avoid using reserved words like 'for', 'while', 'if', 'else', 'def', etc., as variable names to prevent potential conflicts.\n",
    "\n",
    "**Reflecting on our earlier \"KeyError\" examples with 'Sex' and 'Age', it's prudent to consider: **\n",
    "\n",
    "*   **Data Loading:** Did you correctly load the column during `pd.read_csv()`? Is the column named differently in your data source?\n",
    "*   **Column Modifications:** Did you inadvertently remove or rename the column after loading the data?\n",
    "\n",
    "By methodically examining these points and referencing our past conversations, you should be well-equipped to pinpoint and resolve the \"NameError\". If the problem persists, please share the following, and I can provide more tailored support:\n",
    "\n",
    "*   The specific section of code where the \"NameError\" occurs.\n",
    "*   The output of `df.columns` to verify column names in your DataFrame.\n",
    "*   A concise explanation of your goal with the code. \n",
    "\n",
    "\n",
    "### b)\n",
    "\n",
    ">To solve the NameError: name 'x' is not defined error in Python, you need to make sure that the variable is properly defined and assigned a value before it is used. The variable should also be referenced correctly, with the correct case and spelling.\n",
    "\n",
    "## Consensus\n",
    "\n",
    "Both chatbot and search explained that the value `sex` or `age`is not defined, but neither mentioned that the error is due to the parameter requiring a string. But when searching up what parameters `df.groupby()` needs, you can find that it requires a string.\n",
    "\n",
    ">Syntax: DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n",
    "\n",
    ">Parameters :\n",
    "\n",
    ">by : mapping, function, str, or iterable\n",
    "axis : int, default 0\n",
    "level : If the axis is a MultiIndex (hierarchical), group by a particular level or levels\n",
    "as_index : For aggregated output, return object with group labels as the index. Only relevant for DataFrame input. as_index=False is effectively “SQL-style” grouped output\n",
    "sort : Sort group keys. Get better performance by turning this off. Note this does not influence the order of observations within each group. groupby preserves the order of rows within each group.\n",
    "group_keys : When calling apply, add group keys to index to identify pieces\n",
    "squeeze : Reduce the dimensionality of the return type if possible, otherwise return a consistent type\n",
    "\n",
    "Unlike the previous results, the search proved more useful in debugging this error.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "- The chatbot gives answers that are a lot more specific and beginner friendly compared to searches. The chatbot is able to fix your errors and can explain what is wrong with your code.\n",
    "\n",
    "- Searches give answers to your problems, but they tend to be more general, lower quality, and harder to find than the chatbot's solutions. But the search was able to provide answers for more complex questions where the chatbot cannot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d36716",
   "metadata": {},
   "source": [
    "#### 9. Have you reviewed the course [wiki-textbook](https://github.com/pointOfive/stat130chat130/wiki) and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?<br>\n",
    "    \n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> Just answering \"Yes\" or \"No\" or \"Somewhat\" or \"Mostly\" or whatever here is fine as this question isn't a part of the rubric; but, the midterm and final exams may ask questions that are based on the tutorial and lecture materials; and, your own skills will be limited by your familiarity with these materials (which will determine your ability to actually do actual things effectively with these skills... like the course project...)\n",
    "    \n",
    "</details>\n",
    "    \n",
    "***Don't forget to ask for summaries of your ChatBot session(s) and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatGPT)!***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060ae56",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Yes, I reviewed the wiki and interacted with the chatbot.\n",
    "\n",
    "<br>In terms of the summaries:\n",
    "\n",
    "- I used a chatbot to understand the information in this tutorial and lecture.\n",
    "- I used NotebookLM trained on the data from the STA130 repo, So I only have summaries.\n",
    "\n",
    "(Pre lecture)\n",
    "\n",
    "Summary of the Conversation\n",
    "This conversation focuses on exploring a Pokemon dataset using the pandas library in Python. Here's a summary, emphasizing key points from the conversation and connecting them to relevant information from the sources you provided:\n",
    "\n",
    "Goal: Learn about the Pokemon dataset ([1, 2]) The conversation began with you seeking to understand the fundamental characteristics of a Pokemon dataset hosted on GitHub ([3]). The sources, particularly excerpts from course materials like \"STA130F24_TUT01_Sep06.md\" and \"Week-01-Data-Summarization.md,\" provide context for this exploration by emphasizing the use of Python notebooks and ChatBots for data analysis in a course setting.\n",
    "Finding the dimensions of the dataset: You asked how to determine the number of rows and columns in the dataset. The response correctly guided you to use the .shape attribute in pandas ([4-7]). The sources emphasize the importance of understanding attributes like .shape, .dtypes, and .index, which provide information about DataFrame objects without modifying them ([8, 9]).\n",
    "Understanding Observations and Variables: You then asked about the meaning of \"observations\" and \"variables\" in the context of this dataset. The response provided clear definitions: each Pokemon represents an observation (a row in the dataset), and the characteristics of each Pokemon (like Attack and Defense) are the variables (columns in the dataset) ([6, 10, 11]). This aligns with the sources' explanation that observations are typically organized as rows and variables as columns in a dataset.\n",
    "Getting Simple Summaries: You wanted to know how to generate simple summaries of the dataset's columns. The response suggested using the .describe() and .value_counts() methods ([5, 12-17]).\n",
    ".describe() is suitable for numerical data, providing statistics like mean, standard deviation, and percentiles ([4, 15, 18]).\n",
    ".value_counts() is helpful for categorical data, showing the frequency of each unique value in a column ([13, 15, 17]).\n",
    "Discrepancies in df.shape and df.describe() Output: You noticed differences between the output of df.shape and df.describe() regarding the number of columns and the values in the \"count\" column. The response clarified that df.shape considers all columns, while df.describe() focuses on numerical columns by default ([15, 19, 20]). Additionally, the \"count\" in df.describe() represents non-missing values, which might be lower than the total rows if there is missing data ([15, 19, 21, 22]).\n",
    "Attributes vs. Methods: You sought to understand the difference between attributes (like df.shape) and methods (like df.describe()). The response explained that attributes store data about an object, while methods perform actions using that data ([7, 23]).\n",
    "Attributes are accessed without parentheses.\n",
    "Methods are called with parentheses (which can include arguments).\n",
    "The conversation highlights the iterative process of data exploration. You asked progressively more specific questions, demonstrating a developing understanding of the dataset and the tools used to analyze it. The sources played a crucial role by providing background information and explanations of key concepts and techniques, such as handling missing data, data types, and the distinction between attributes and methods in Python.\n",
    "\n",
    "The conversation, however, does not explore more advanced data manipulation techniques like imputing missing values, which are mentioned as \"out of scope\" in the provided source materials ([24-29]).\n",
    "\n",
    "(Post Lecture)\n",
    "\n",
    "\n",
    "Here is a summary of the conversation so far concerning the pandas .describe() method, and the appropriate use cases for df.dropna() and del df['col'] when working with missing data.\n",
    "\n",
    "The Conversation Began with an Explanation of the df.describe() Method:\n",
    "This method is used to quickly generate descriptive statistics for numerical columns in a pandas DataFrame. [1, 2]\n",
    "It provides the 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max' for each applicable column. [1, 2]\n",
    "Importantly, df.describe() automatically excludes missing values in its calculations. The 'count' statistic reflects this by indicating the number of non-missing values. [1, 3, 4]\n",
    "It's crucial to remember that df.describe() is designed for numerical data and will exclude non-numeric columns. [1, 4]\n",
    "The Discussion then Shifted to Handling Missing Data, Contrasting df.dropna() and del df['col']:\n",
    "Scenario Where df.dropna() is Favored: When you have a dataset where a column has some missing values, but the other data in rows with those missing values is still useful. [5-7]\n",
    "For example, if you were analyzing house prices and had a column for \"year built\" that was missing some data, using df.dropna() would only remove the rows where \"year built\" is missing, preserving data about \"price,\" \"square footage,\" and other relevant features in those rows.\n",
    "Scenario Where del df['col'] is Favored: This is preferable when a column has a very high percentage of missing data, making it unreliable, and the information in that column is not crucial to your analysis. [6-8]\n",
    "An example provided was a marketing campaign dataset where 80% of respondents did not answer a survey. Deleting the entire \"survey responses\" column with del df['col'] would be more practical than using df.dropna() and losing 80% of the data, especially if other columns like \"purchase history\" are more central to your analysis.\n",
    "Finally, the Importance of the Order of Applying del df['col'] and df.dropna() was Explained:\n",
    "It is often more efficient to use del df['col'] before df.dropna() when both are needed to clean a dataset. [9, 10]\n",
    "This ensures that you first remove the problematic column (with a large amount of missing data) and then apply df.dropna() to the remaining columns. [9]\n",
    "This order prevents you from losing rows that might have had missing values in the column you deleted anyway. [9]\n",
    "\n",
    "\n",
    "### Summary of Conversation about `df.groupby()`\n",
    "\n",
    "You expressed interest in understanding the Pandas code `df.groupby(\"col1\")[\"col2\"].describe()` in the context of the Titanic dataset, which you are analyzing.   You had already downloaded the dataset from the provided URL.\n",
    "\n",
    "**Explanation of the Code:**\n",
    "\n",
    "*   **`df.groupby(\"col1\")`**: This part of the code divides the DataFrame (`df`) into groups based on the unique values in the column named \"col1\".  For example, if \"col1\" represents \"passenger class\" in the Titanic dataset, this code would create separate groups for 'First', 'Second', and 'Third' class passengers.\n",
    "*   **`[\"col2\"]`**: This selects the column specified by \"col2\" from each of the groups created in the previous step.  Essentially, you are now focusing on a specific variable (represented by \"col2\") within each group.\n",
    "*   **`.describe()`**: This calculates descriptive statistics for the data in \"col2\" *within each group*. These statistics provide a summary of the data distribution, such as:\n",
    "    *   Count (number of non-null values)\n",
    "    *   Mean (average value)\n",
    "    *   Standard Deviation (measure of data spread)\n",
    "    *   Minimum and Maximum values\n",
    "    *   Percentiles (25th, 50th/Median, 75th)\n",
    "\n",
    "**Example using the Titanic Dataset:**\n",
    "\n",
    "To understand how the age of passengers (\"age\") varies across passenger classes (\"pclass\") in the Titanic dataset, you can use:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have already loaded the Titanic data into a DataFrame called 'titanic_df'\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic_df = pd.read_csv(url)\n",
    "\n",
    "titanic_df.groupby(\"pclass\")[\"age\"].describe() \n",
    "```\n",
    "\n",
    "This code will generate a table where each row represents a passenger class (\"pclass\"), and the columns display the descriptive statistics of age for passengers belonging to that class.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "*   The `.describe()` method automatically handles missing values by excluding them from calculations. \n",
    "*   This approach is most informative when \"col2\" (in this example, \"age\") is a numerical column since you are calculating numerical summaries. If the column contains non-numeric (categorical) data,  `df['x'].value_counts()` would be more appropriate.\n",
    "\n",
    "The conversation highlighted the usefulness of `df.groupby(\"col1\")[\"col2\"].describe()` for gaining insights into how a variable of interest (\"col2\") is distributed across different categories or groups defined by another variable (\"col1\").\n",
    "\n",
    "\n",
    "# Summary of the very long question 8.3\n",
    "\n",
    "Here is a summary of your conversation:\n",
    "\n",
    "You received multiple \"KeyError\" and \"NameError\" messages while coding in Python with the pandas library. These errors typically occur when trying to access a column or variable that doesn't exist as specified. The errors suggested potential issues with case sensitivity, typos, variable definition, and column access.\n",
    "\n",
    "**Breakdown of Errors and Troubleshooting Steps:**\n",
    "\n",
    "*   **KeyError: 'Sex'**:  You likely attempted to access a DataFrame column named 'Sex', but the actual column name might have been 'sex'. Python is case-sensitive, so these names are considered different.\n",
    "*   **KeyError: 'Column not found: Age'**:  Similar to the 'Sex' error, you might have tried to access a column named 'Age', while the correct name could be 'age'. The sources emphasize that Python is case-sensitive, particularly in the context of \"KeyError\" messages (refer to the conversation about 'Sex' and 'Age' column errors). \n",
    "*   **NameError: name 'age' is not defined**: This error indicated that Python didn't recognize 'age' as a defined variable or object.  The sources highlight that this error usually happens when using a variable before it's defined or assigned a value. \n",
    "*   **NameError: name 'sex' is not defined**:  Similar to the 'age' \"NameError\", this error meant Python couldn't find a defined entity named 'sex'.  This issue likely stemmed from not defining 'sex' as a variable, a typo in the name, or attempting to access it outside its scope.\n",
    "\n",
    "**Drawing on the Sources and Our Conversation**\n",
    "\n",
    "The consistent theme across these errors is the importance of meticulous attention to detail, particularly regarding case sensitivity and typos. The sources stress how common these errors are.\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "*   **Case Sensitivity:** Always double-check the capitalization of column names and variables. \n",
    "*   **Typos:**  Carefully review your code for any spelling errors in names.\n",
    "*   **Variable and Column Definitions:**  Ensure that variables are defined and assigned values before use and that column names match those in your DataFrame. \n",
    "\n",
    "The conversation highlighted the significance of understanding error messages in Python and leveraging past experiences and available resources to troubleshoot effectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce11ef1",
   "metadata": {},
   "source": [
    "# Recommended Additional Useful Activities [Optional]\n",
    "\n",
    "The \"Ethical Profesionalism Considerations\" and \"Current Course Project Capability Level\" sections below **are not a part of the required homework assignment**; rather, they are regular weekly guides covering (a) relevant considerations regarding professional and ethical conduct, and (b) the analysis steps for the STA130 course project that are feasible at the current stage of the course<br><br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Ethical Professionalism Considerations</u></summary>\n",
    "\n",
    "## Ethical Professionalism Considerations\n",
    "\n",
    "> If the observed data is \"no events occured\" does this mean the data is \"missing\" and [should be ignored](https://priceonomics.com/the-space-shuttle-challenger-explosion-and-the-o)?\n",
    "> \n",
    "> - NASA: \\<determines temperature doesn't affects \"o-ring\" by subseting data to just \"o-ring\" incidents\\>\n",
    "> - Also NASA: \\<launches the shuttle on a cold day\\>\n",
    "\n",
    "|No apparent \"o-ring\" failure and temperature relationship|Apparent between \"o-ring\" failure and temperature relationship|\n",
    "|:-|:-|\n",
    "if you just look at \"o-ring\" failure event data|if you instead look at ALL the data as you should|\n",
    "|![](https://etzq49yfnmd.exactdn.com/wp-content/uploads/2022/03/image06-14.png)|![](https://etzq49yfnmd.exactdn.com/wp-content/uploads/2022/03/image02-33.png)|\n",
    "|![](https://upload.wikimedia.org/wikipedia/commons/8/8b/Shuttle_Challenger_explosion.gif?20190203170223)|![](https://i.makeagif.com/media/10-04-2014/nT57xW.gif)|\n",
    "\n",
    "<br>\n",
    "    \n",
    "</details>    \n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Current Course Project Capability Level</u></summary>\n",
    "\n",
    "## Current Course Project Capability Level\n",
    "\n",
    "> The data we'll use for the STA130 course project is based on the [Canadian Social Connection Survey](https://casch.org/cscs). Please see the [data use agreement](https://static1.squarespace.com/static/60283c2e174c122f8ebe0f39/t/6239c284d610f76fed5a2e69/1647952517436/Data+Use+Agreement+for+the+Canadian+Social+Connection+Survey.pdf) regarding the appropriate and ethical professional use of this data (available at the bottom of the [CSCS](https://casch.org/cscs) webpage).\n",
    "> \n",
    "> 1. Have a very quick look at the list of available variables available using the [link](https://drive.google.com/file/d/1ISVymGn-WR1lcRs4psIym2N3or5onNBi/view) (again at the bottom of the [CSCS](https://casch.org/cscs) webpage); then, \n",
    "> 2. examine the code in the first thirteen code cells of [STA130F24_CourseProject.ipynb](https://github.com/pointOfive/stat130chat130/blob/main/CP/STA130F24_CourseProject.ipynb) to get an initital understanding of how we might subset to different studies included in the [data](https://drive.google.com/file/d/1mbUQlMTrNYA7Ly5eImVRBn16Ehy9Lggo/view) (again accessible at the bottom of the [CSCS](https://casch.org/cscs) webpage); then,     \n",
    "> 3. review the fourteenth and fifteenth cells (with the comments \"Here's a high level summary of the data\" and \"And here are some explanations about the columns in the data\") a little more closely to get a better sense of which columns seem to be the most interesting and whether or not they seem to have a lot of missing data\n",
    "    \n",
    "</details>        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ca7d22",
   "metadata": {},
   "source": [
    "### Afterward\n",
    "\n",
    "Here are few ideas of some other kinds of interactions you might consider exploring with a ChatBot...\n",
    "\n",
    "> While these are likely to be extremely practically valuable, they are not a part of the homework assignment, so do not include anything related to these in your homework submission\n",
    "\n",
    "- With respect to improving ones ability in statistics, coding, communication, and other key data science skills\n",
    "    - what is the ChatBots perception its own capabilities and uses as an AI-driven assistance tool \n",
    "    - and does ChatBots assessment of itself influence or agree with your own evalution of the ChatBot? \n",
    "\n",
    "- ChatBots can introduce and explain the \"World War 2 planes\" problem and the \"Monte Hall\" problem... \n",
    "    - how well does do they seem to do and introducing and explaining other \"unintuitive surprising statistics paradoxes\"?\n",
    "\n",
    "- If you consider the process of writing about why you chose to take this course, and the skills you were hoping to build through this course with respect to your current ideas about what possible careers \n",
    "    - and how do you think the exercise would be different if you framed it as a dialogue with a ChatBot\n",
    "    - and do you think the difference could be positive and productive, or potentially biasing and distracting?\n",
    "    \n",
    "- ChatBots sometimes immediately responds in simple helpful ways, but other times it gives a lot of extraneous information that can be overwheling... are you able to prompt and interact with ChatBots in manner that keeps its reponses helpful and focused on what you're interested in? \n",
    "\n",
    "- ChatBots tends to respond in a fairly empathetic and supportive tone...\n",
    "    - do you find it helpful to discuss concerns you might have about succeeding in the course (or entering university more generally) with a ChatBot?\n",
    "    \n",
    "- For what purposes and in what contexts do you think a ChatBot could provide suggestions or feedback about your experiences that might be useful? \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
